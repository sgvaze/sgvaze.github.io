<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Sagar Vaze</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar">
						<img src="images/avatar.jpg" alt="" /></a>
						<h1>
							<p style="margin: 0; padding: 0"><strong>Sagar Vaze</strong></p>
							<p style="margin: 0; padding: 0">Machine Learning and Computer Vision</p>
							<p style="margin: 0; padding: 0">PhD Student at Oxford University</p>
							<p style="margin: 0; padding: 0">Working in the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a></p>
						</h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2>About<br />
							</h2>
						</header>
						<p>
							I'm a PhD student in the Visual Geometry Group at Oxford
							University, co-supervised by <a href="http://scholar.google.co.uk/citations?hl=en&user=UZ5wscMAAAAJ">Prof. Andrew Zisserman</a> and
							<a href="http://www.robots.ox.ac.uk/~vedaldi/">Prof. Andrea Vedaldi</a>.
							I am currently interning with <a href="https://imisra.github.io/">Ishan Misra</a> at FAIR New York.

							I previously studied Engineering Science, also at Oxford, graduating in 2018.
							In between graduating and beginning my PhD, I was fortunate to work at <a href="https://fi.linkedin.com/company/the-curious-ai-company">CuriousAI</a> in Helsinki (now acquired by Apple)
							and <a href="https://foundersfactory.com/">Founders Factory</a> in London. I have since continued to work with start-ups when time allows. My research is funded by a Facebook AI Research Scholarship.
						</p>

						<p>
							<papertitle><a href="https://scholar.google.com/citations?user=lvuOknUAAAAJ&hl=en">Google Scholar</a></papertitle> / <papertitle><a href="images/Sagar Vaze Resume.pdf">CV</a></papertitle>
						</p>
					</section>

				<!-- Two -->
					<section id="two">
						<h2>Project Pages</h2>
						<div class="row">
							<article class="col-6 col-12-xsmall work-item">
								<a href="pages/lightweight_unets.html" class="image fit thumb"><img src="images/thumbs/lightweight_unets.png" alt=""/></a>
								<h3>Lightweight U-Nets: Efficient CNNs for fast medical image analysis</h3>
								<p>Work conducted during my time at the <a href="https://omni.cs.ox.ac.uk/">Machine Learning in Neuroimaging Lab</a> in the IBME, Univeristy of Oxford</p>
							</article>
						</div>
						<!--
						<ul class="actions">
							<li><a href="#" class="button">All Posts</a></li>
						</ul>
						<-->
					</section>

				<!-- Three -->
					<section id="three">
						<h2>Research</h2>

						<p>
							My research focuses on Open World Learning - I am interested in learning representations from limited (labelled) training sets
							which can generalize to 'open world' data, where the data distribution (e.g categories or domain) may be different.

						</p>

<!--							<h3>Pre-print</h3>-->

							<h3>Conference</h3>

								<p> </p>
								<a href="">
									<papertitle>Generalized Category Discovery</papertitle>
								</a>
								<br>
								<strong>Sagar  Vaze</strong>,
								Kai Han, Andrea Vedaldi, Andrew Zisserman <br>
								CVPR, 2022. <br>
								<a href="https://arxiv.org/abs/2201.02609">Paper</a> /
								<a href="https://github.com/sgvaze/generalized-category-discovery">Code</a>
								<p> </p>

								<p> </p>
								<a href="">
									<papertitle>Open-Set Recognition: A Good Closed-Set Classifier is All You Need</papertitle>
								</a>
								<br>
								<strong>Sagar  Vaze</strong>,
								Kai Han, Andrea Vedaldi, Andrew Zisserman <br>
								ICLR, 2022 (Oral, 1.6% of submissions). <br>
								<a href="https://arxiv.org/abs/2110.06207">Paper</a> /
								<a href="https://github.com/sgvaze/osr_closed_set_all_you_need">Code</a>
								<p> </p>

								<p> </p>
								<a href="">
									<papertitle>Semantically Grounded Object Matching for Robust Robotic Scene Rearrangement</papertitle>
								</a>
								<br>
								Walter Goodwin, <strong>Sagar  Vaze</strong>, Ioannis Havoutis, Ingmar Posner
								<br>
								ICRA, 2022. <br>
								<a href="https://arxiv.org/abs/2111.07975">Paper</a> /
								<a href="https://github.com/applied-ai-lab/object_matching">Code</a>
								<p> </p>

							<h3>Journal</h3>
								<p> </p>
								  <a href="">
									<papertitle>Low-Memory CNNs Enabling Real-Time Ultrasound Segmentation Towards Mobile Deployment</papertitle>
								  </a>
								  <br>
								  <strong>Sagar  Vaze</strong>,
								  Weidi Xie, Ana Namburete <br>
								  In: <em>IEEE Journal of Biomedical and Health Informatics (Impact Factor: ~4.2) </em>, 2020. <br>
								  <a href="https://ieeexplore.ieee.org/document/8999615">Paper</a> /
								  <a href="https://sgvaze.github.io/pages/lightweight_unets.html">Project Page</a> /
								  <a href="https://github.com/sgvaze/lightweight_unet">Code</a>
								  <p> </p>

							<h3>Workshop</h3>
								<p> </p>
								  <a href="">
									<papertitle>Optimal Use of Multi-spectral Satellite Data with Convolutional Neural Networks</papertitle>
								  </a>
								  <br>
								  <strong>Sagar Vaze</strong>, Conrad James Foley, Mohamed El Amine Seddiq, Alexey Unagaev, Natalia Efremova <br>
								  In: <em>AI For Social Good (With Harvard CRCS)</em>, 2020. <br>
								  <a href="https://arxiv.org/abs/2009.07000">Paper</a>
								  <p> </p>

								<p> </p>
								  <a href="">
									<papertitle>SMArtCast: Predicting soil moisture interpolations into the future using Earth observation data in a deep learning framework</papertitle>
								  </a>
								  <br>
								  Conrad James Foley, <strong>Sagar Vaze</strong>, Mohamed El Amine Seddiq, Alexey Unagaev, Natalia Efremova <br>
								  In: <em>Climate Change AI (In conjunction with ICLR) </em>, 2020. <br>
								  <a href="https://arxiv.org/abs/2003.10823">Paper</a>
								  <p> </p>

								<p> </p>
								  <a href="">
									<papertitle>Segmentation of Fetal Adipose Tissue Using Efficient CNNs for Portable Ultrasound</papertitle>
								  </a>
								  <br>
								  <strong>Sagar Vaze</strong>, Ana Namburete <br>
								  In: <em>Perinatal, Preterm and Paediatric Image analysis (PIPPI, in conjunction with MICCAI) </em>, 2018. <br>
								  <a href="https://link.springer.com/chapter/10.1007/978-3-030-00807-9_6">Paper</a>
								  <p> </p>

						<!--
						<ul class="actions">
							<li><a href="#" class="button">All Posts</a></li>
						</ul>
						<-->
					</section>
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://scholar.google.com/citations?user=lvuOknUAAAAJ&hl=en" class="icon brands fa-google"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://uk.linkedin.com/in/sagar-vaze-2356ab171" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/sgvaze" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://twitter.com/Sagar_Vaze" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="mailto: remove-this-if-youre-human-sagar@robots.ox.ac.uk" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>