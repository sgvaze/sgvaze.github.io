<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1000px;
}
h1 {
    font-weight:300;
}

.disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
}

video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

a:link,a:visited
{
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
  }

  td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
  }

  .vert-cent {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

<html>
<head>
<title>Open-Set Recognition Revisited: a modern baseline and new benchmarks</title>
<meta property="og:image" content="../images/rural_ultrasound.jpg"/>
<meta property="og:title" content="Open-Set Recognition Revisited: a modern baseline and new benchmarks. In Arxiv, 2021." />
</head>

<body>
<br>
<center>
    <span style="font-size:42px">Open-Set Recognition Revisited: a modern baseline and new benchmarks</span><br>

    <table align=center width=1000px>
        <tr>
            <td align=center width=1000px>
                <span style="font-size:22px"><a href="https://sgvaze.github.io/">Sagar Vaze</a></span> &emsp;
                <span style="font-size:22px"><a href="http://www.kaihan.org/">Kai Han</a></span> &emsp;
                <span style="font-size:22px"><a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a></span> &emsp;
                <span style="font-size:22px"><a href="http://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a></span>
            </td>
        </tr>
    </table>



    <span style="font-size:22px">Visual Geometry Group, University of Oxford</span>
    <br>
    <br>

    <table align=center width=900px>
        <tr>
            <td align=center width=300px>
                <span style="font-size:22px"><a href=''> Paper [Arxiv 2021]</a></span> &emsp;&emsp;
                <span style="font-size:22px"><a href=''> Code [PyTorch]</a></span>

            </td>
        </tr>
    </table>
</center>
<br>

<table align=center width=800px>
    <tr>
        <td width=600px>
            <center>
                <img class="rounded" src = "../images/modernising_osr_teaser_fig.png" height="270px"></img>
                <br>
            </center>
        </td>
    </tr>
</table>

<br>

<hr>

<table align=center width=900px>
    <center><h1>Summary</h1></center>
    <p>
        Open-set recognition (OSR) is the task of identifying if the class of an evaluation image belongs to one of the classes in a model's training set.
        Here we show that simply training the baseline method properly (training with the cross-entropy loss and using the softmax confidence of the predicted class as an OSR indicator) can outperform state-of-the-art methods.
        We further suggest new benchmark datasets which have clearer definitions of what constitutes a semantic class.
    </p>
</table>
<hr>

<hr>

<table align=center width=900px>
    <center><h1>Abstract</h1></center>
    <p>
        Open-set recognition (OSR) is the task of identifying if the class of an evaluation image belongs to one of the classes in a model's training set.
        In this paper we reappraise the recent methods and benchmarks for this task.
        We make four contributions. First, we establish a correlation between the closed-set and open-set performance of a classifier, that holds over datasets and methods, and give an analysis of this in terms of feature norms.
        Second, building on this correlation, we show that the performance of a standard baseline open-set classifier can be enhanced
        significantly by using modern training methods for closed-set classifiers.
        This improved baseline significantly closes the gap to state-of-the-art OSR models and substantially outperforms all previous methods on the most challenging TinyImageNet benchmark.
        Third, we show that training a state-of-the-art OSR method on top of our improved baseline can boost its OSR performance, but that the increment over the baseline is now much reduced.
        Finally, we propose the use of fine-grained visual categorization datasets for OSR, constructing new benchmark splits with varying difficulty, and evaluating the baseline and state-of-the-art methods in this new setting.    </p>
</table>
<hr>

<table align=center width=900px>
    <center><h1>BibTex</h1></center>
        <!-- <pre> -->
        <pre style="background-color: #e2e2e2; border: 1px dotted #818181; padding: 5px;">
            <span class="inner-pre" style="font-size: 14px">
  @article{vaze21openset,
    author  = {Sagar Vaze and Kai Han and Andrea Vedaldi and Andrew Zisserman},
    title   = {Open-Set Recognition Revisited: a modern baseline and new benchmarks},
    journal = {arXiv preprint},
    year    = {2021},
  }
</span>
        </pre>
</table>
<hr>

<table align=center width=1000px>
    <tr>
        <td width=400px>
            <left>
            <center><h1>Acknowledgments</h1></center>
            This work is supported by the EPSRC Programme Grant Seebibyte EP/M013774/1. We also gratefully acknowledge the
            support of Facebook Research and Nielsen.
            </left>
        </td>
    </tr>
</table>

<br><br>
<p style="text-align:center;font-size:16px;">
    Webpage template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
</p>
</body>
</html>